{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SETUP THE ENVIRONMENT"
      ],
      "metadata": {
        "id": "2ZOULqtSrPGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylIOie2xqXlD"
      },
      "outputs": [],
      "source": [
        "!pip install -U pip\n",
        "!pip install accelerate\n",
        "!pip install appdirs\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install fire\n",
        "!pip install git+https://github.com/huggingface/peft.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install torch\n",
        "!pip install sentencepiece\n",
        "!pip install tensorboardX\n",
        "!pip install gradio\n",
        "!pip install -U transformers tokenizers\n",
        "!pip install scipy\n",
        "!pip install seaborn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT AND INITIALISE MODEL AND TOKENIZER"
      ],
      "metadata": {
        "id": "QAlzCAyJrSy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "from huggingface_hub import notebook_login\n",
        "import gc\n",
        "notebook_login()\n",
        "\n",
        "\n",
        "from transformers import AdamW,get_scheduler\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import transformers\n",
        "import textwrap\n",
        "from transformers import Trainer\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorWithPadding\n",
        "import os\n",
        "import sys\n",
        "from typing import List\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    prepare_model_for_int8_training,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import fire\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import json\n",
        "import datasets\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import LlamaTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification, \\\n",
        "    DataCollatorForTokenClassification\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(rc={'figure.figsize':(8, 6)})\n",
        "sns.set(rc={'figure.dpi':100})\n",
        "sns.set(style='white', palette='muted', font_scale=1.2)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "candidate_labels = [\"attack\", \"normal\"]\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"togethercomputer/LLaMA-2-7B-32K\",\n",
        "                                                           load_in_8bit=True,\n",
        "                                                           torch_dtype=torch.float16,\n",
        "                                                           device_map=\"auto\", num_labels=2)\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"togethercomputer/LLaMA-2-7B-32K\")\n"
      ],
      "metadata": {
        "id": "V4rZ7NDfqaFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD THE DATASET FROM HUGGINGFACE ( ELSE USE THE ONE ALREADY MAPPED AND STORED)"
      ],
      "metadata": {
        "id": "PN4YsdRfrcTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets\n",
        "# #LABELS ALREADY IN PLACE , tokenize the input strings\n",
        "\n",
        "\n",
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# def tokenize_function(example):\n",
        "#     return tokenizer(example[\"text\"],truncation=True, padding=False)\n",
        "\n",
        "\n",
        "# model_features = datasets.Features(\n",
        "#         {'text': datasets.Value('string'), 'label': datasets.ClassLabel(num_classes=2,names=candidate_labels)})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train_data2 = load_dataset(\"niting3c/malicious-packet-analysis\",data_dir=\"network-packet-flow-header-payload\",split=\"train\",features=model_features).map(tokenize_function,batched=True)\n",
        "\n",
        "# val_data = load_dataset(\"niting3c/malicious-packet-analysis\",data_dir=\"network-packet-flow-header-payload\",split=\"test\",features=model_features).map(tokenize_function,batched=True)\n",
        "\n",
        "# test_data = load_dataset(\"niting3c/malicious-packet-analysis\",data_dir=\"metasploitable-data\",split=\"test\",features=model_features).map(tokenize_function,batched=True)\n",
        "# train_data1 = load_dataset(\"niting3c/malicious-packet-analysis\",data_dir=\"normal_netresc\",features=model_features).map(tokenize_function,batched=True)\n",
        "# try:\n",
        "#     test_data = test_data.remove_columns('text')\n",
        "#     test_data = test_data.rename_column(\"label\", \"labels\")\n",
        "#     test_data.set_format(\"torch\")\n",
        "#     test_data.column_names\n",
        "# except ValueError as e :\n",
        "#     print(e)\n",
        "\n",
        "\n",
        "# try:\n",
        "#     train_data2 = train_data2.remove_columns('text')\n",
        "#     train_data2 = train_data2.rename_column(\"label\", \"labels\")\n",
        "#     train_data2.set_format(\"torch\")\n",
        "#     train_data2.column_names\n",
        "# except ValueError as e :\n",
        "#     print(e)\n",
        "# try:\n",
        "#     train_data1 = train_data1.remove_columns('text')\n",
        "#     train_data1 = train_data1.rename_column(\"label\", \"labels\")\n",
        "#     train_data1.set_format(\"torch\")\n",
        "#     train_data1.column_names\n",
        "# except ValueError as e :\n",
        "#     print(e)\n",
        "# try:\n",
        "#     val_data = val_data.remove_columns('text')\n",
        "#     val_data = val_data.rename_column(\"label\", \"labels\")\n",
        "#     val_data.set_format(\"torch\")\n",
        "#     val_data.column_names\n",
        "# except ValueError as e :\n",
        "#     print(e)\n"
      ],
      "metadata": {
        "id": "qXVQwNUGqr9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "USING THE STORED DATA SET AND LOADING FROM DISK TO SAVE COMPUTE"
      ],
      "metadata": {
        "id": "zC-qdUAVrh-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data1=load_from_disk(\"data/train_data1\")[\"train\"]\n",
        "train_data2=load_from_disk(\"data/train_data2\")\n",
        "val_data=load_from_disk(\"data/val_data\")\n",
        "test_data=load_from_disk(\"data/test_data\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "train_data_1_loader = DataLoader(\n",
        "    train_data1, shuffle=True, batch_size=2, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "train_data_2_loader  = DataLoader(\n",
        "    train_data2, shuffle=True, batch_size=2, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "test_data_loader = DataLoader(\n",
        "    test_data,  batch_size=2, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_data, batch_size=2, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "for batch in train_data_1_loader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "id": "nnkDHXEGqwsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLEAR SOME CACHE AND MEMORY"
      ],
      "metadata": {
        "id": "-mu0Rblgrng9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "4uULLtIrrNCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "START TRAINING THE MODEL\n"
      ],
      "metadata": {
        "id": "XoByxWdVrppc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"heuristic\"\n",
        "model.train()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "device\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_data_1_loader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)\n"
      ],
      "metadata": {
        "id": "5tHaAtMkq2-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for batch in train_data_1_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "R1rHFAovq8LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-9B06Ivq8Ej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}